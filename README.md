


# GEN---AI-COURSE

A curated set of AI-powered projects showcasing applications of NLP, multi-modal learning, document retrieval, and semantic search.

---

## ğŸ“ Project Structure

```

GEN---AI-COURSE/
â”œâ”€â”€ customer_service_chatbot_LLM/
â”‚ â”œâ”€â”€ dataset/
â”‚ â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ README.md
â”‚ â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ LLM/
â”‚ â”œâ”€â”€ End-To-End-Gemini-Project-main/
â”‚ â”œâ”€â”€ llama3/
â”‚ â”œâ”€â”€ intro_palm_api.ipynb
â”‚ â””â”€â”€ python.ipynb
â”‚
â”œâ”€â”€ NLP/
â”‚ â”œâ”€â”€ NLP_bot/
â”‚ â”œâ”€â”€ NLP (1).ipynb
â”‚ â”œâ”€â”€ NLP_Word2vec.ipynb
â”‚ â””â”€â”€ SMSSpamCollection.txt
â”‚
â”œâ”€â”€ Task 1 (Article-Generator)/
â”‚   â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ Task 2 (Multi-Modal-Chatbot)/
â”‚   â”œâ”€â”€ App/
â”‚   â”‚   â”œâ”€â”€ .env
â”‚   â”‚   â””â”€â”€ app.py
â”‚   â”œâ”€â”€ Model/
â”‚   â”‚   â”œâ”€â”€ chatbot\_intent\_classifier.pkl
â”‚   â”‚   â”œâ”€â”€ model.ipynb
â”‚   â”‚   â””â”€â”€ tfidf\_vectorizer.pkl
â”‚   â”œâ”€â”€ Visuals/
â”‚   â”œâ”€â”€ Readme.md
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ Task 3 (MedQuAD-Chatbot)/
â”‚   â”œâ”€â”€ App/
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â””â”€â”€ label\_encoder.pkl
â”‚   â”‚
â”‚   â”œâ”€â”€ MedQuAD/
â”‚   â”œâ”€â”€ Model/
â”‚   â”‚   â”œâ”€â”€ label\_encoder.pkl
â”‚   â”‚   â”œâ”€â”€ medquad.json
â”‚   â”‚   â”œâ”€â”€ rf\_tfidf\_model.pkl
â”‚   â”‚   â”œâ”€â”€ tfidf\_vectorizer.pkl
â”‚   â”‚   â””â”€â”€ train\_medquad\_model.ipynb
â”‚   â”œâ”€â”€ confusion\_matrix.png
â”‚   â”œâ”€â”€ new\_parse.py
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ Task 4 (arxiv-Chatbot)/
â”‚   â”œâ”€â”€ App/
â”‚   â”‚   â””â”€â”€ app.py
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ arxiv\_embeddings\_drive\_link.txt
â”‚   â”‚   â””â”€â”€ arxiv\_embeddings.pkl
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ model\_accuracy.ipynb
â”‚   â”‚   â””â”€â”€ model\_training.ipynb
â”‚   â”œâ”€â”€ resources/
â”‚   â”‚   â”œâ”€â”€ arxiv-metadata-oai-snapshot\_drive\_link.txt
â”‚   â”‚   â””â”€â”€ arxiv-metadata-oai-snapshot.json
â”‚   â”œâ”€â”€ visuals/
â”‚   â”‚   â””â”€â”€ Confusion\_matrix.png
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ Task 5 (Emotion-Chatbot)/
â”‚ â”œâ”€â”€ App/
â”‚ â”œâ”€â”€ .env
â”‚ â”œâ”€â”€ main.py
â”‚ â””â”€â”€ Model/
â”‚ â”œâ”€â”€ emotion_dataset/
â”‚ â”œâ”€â”€ model.ipynb
â”‚ â””â”€â”€ training.ipynb


````

---

## ğŸ“Œ Project Tasks

### ğŸ”¹ Task 1: Article Generator
- Generates AI-written articles based on user-provided topics or prompts.
- NLP techniques like keyword extraction and summarization used.
- Streamlit-based frontend for user interaction (`app/` directory).
- Modular design for easy integration of new generation models.

### ğŸ”¹ Task 2: Multi-Modal Chatbot
- Integrates both text and potential vision-based input (if extended).
- Uses a trained intent classification model (`chatbot_intent_classifier.pkl`) with TF-IDF vectorization.
- Frontend built with Streamlit (`app.py`).
- Dependencies listed in `requirements.txt`.

### ğŸ”¹ Task 3: MedQuAD Chatbot
- Q&A bot trained on NIH MedQuAD dataset.
- Uses TF-IDF with Random Forest classification.
- Includes semantic label encoder and JSON-based question-answer dataset.
- Accuracy and confusion matrix visual included.

### ğŸ”¹ Task 4: arxiv Chatbot
- Designed for document summarization and semantic search on arXiv papers.
- Embeddings generated and stored (`arxiv_embeddings.pkl`).
- Metadata handled via `arxiv-metadata-oai-snapshot.json`.
- Model training and evaluation in dedicated notebooks.

### ğŸ”¹ Task 5: Emotion-Based Chatbot
- Detects emotions in user input (e.g., joy, anger, sadness) using a trained classifier.
- Provides emotionally aware responses to enhance user experience.
- Includes `Streamlit-based interaction (`main.py`).
- Dataset and training notebooks available under the `Model/` directory.

---

## ğŸ’» Getting Started

```bash
# Clone the repository
git clone https://github.com/your-username/GEN---AI-COURSE.git
cd GEN---AI-COURSE

# Install requirements for a specific task
cd "Task 3 (MedQuAD-Chatbot)"
pip install -r requirements.txt

# Run the Streamlit app
streamlit run App/app.py
````

---

## ğŸ“œ License

This project is provided for academic and learning purposes.

---

## ğŸ™ Acknowledgements

* NIH MedQuAD Dataset
* arXiv Open Access Metadata
* HuggingFace Transformers
* Scikit-learn
* Streamlit

```

Let me know if you'd like me to **create individual `README.md` files** for each task folder too.
```
